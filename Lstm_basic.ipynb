{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0988530033195076, 0.07816074424219795, 0.11922103810381644, 0.0004367702687530472], [0.09923030485889503, 0.08121091962725933, 0.11768764854621108, 0.0006885160770312606], [0.10224871717399449, 0.08235473539665734, 0.11998773288261912, 0.0010407458428446843], [0.10300332025276936, 0.0857861827048514, 0.12688798589184322, 0.0016906760801824242], [0.1090401448829683, 0.08616745462798407, 0.12727133328124457, 0.001759675064356602], [0.10941744642235574, 0.09608052462943358, 0.12535459633423787, 0.00387452742394766], [0.1135677633556175, 0.09684306847569892, 0.13302154412226463, 0.0021058757927179127], [0.1158315725919421, 0.09684306847569892, 0.13877175496328473, 0.0006652037988830918], [0.1180953818282667, 0.10065578770702564, 0.1395384497420874, 0.0016585212137711568], [0.11998188952520387, 0.10713741040028109, 0.13723836540567938, 0.003821203937148975]] -> [[0.11561834109292385], [0.11246152631905562], [0.1191697577135256], [0.11127772077885503], [0.10378028569091799], [0.10969931339192092], [0.10891010969845387], [0.11048851708538798], [0.11759135032659149], [0.12311577618086089]]\n",
      "훈련 데이터의 크기 : (1390, 10, 4) (1390, 10, 1)\n",
      "테스트 데이터의 크기 : (597, 10, 4) (597, 10, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 20)            2000      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 20)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,301\n",
      "Trainable params: 5,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/70\n",
      "47/47 [==============================] - 2s 4ms/step - loss: 0.0429\n",
      "Epoch 2/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 3/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 4/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 5/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 6/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 7/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 8/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 9/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 10/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 11/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 12/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 13/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 14/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 15/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 16/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 17/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 18/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 19/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 20/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 21/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 22/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 23/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 24/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 25/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 26/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 27/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 28/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 29/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 30/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 31/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 32/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 33/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 34/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 35/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 36/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 37/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 38/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 39/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 40/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 41/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 42/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 43/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 44/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 45/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 46/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 47/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 48/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 49/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 50/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 51/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 52/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 53/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 54/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 55/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 56/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 57/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 58/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 59/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 60/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 61/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 62/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 63/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 64/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 65/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 66/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 67/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 68/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 69/70\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 70/70\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = fdr.DataReader('004840','2015')\n",
    "def MinMaxScaler(data):\n",
    "    \"\"\"최솟값과 최댓값을 이용하여 0 ~ 1 값으로 변환\"\"\"\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # 0으로 나누기 에러가 발생하지 않도록 매우 작은 값(1e-7)을 더해서 나눔\n",
    "    return numerator / (denominator + 1e-7)\n",
    "dfx = df[['Open','High','Low','Volume', 'Close']]\n",
    "dfx = MinMaxScaler(dfx)\n",
    "dfy = dfx[['Close']]\n",
    "dfx = dfx[['Open','High','Low','Volume']]\n",
    "dfx\n",
    "X = dfx.values.tolist()\n",
    "y = dfy.values.tolist()\n",
    "window_size = 10\n",
    "window_size2= 20\n",
    "data_X = []\n",
    "data_y = []\n",
    "for i in range(len(y) - window_size2):\n",
    "    _X = X[i : i + window_size] # 다음 날 종가(i+windows_size)는 포함되지 않음\n",
    "    _y = y[i + window_size:i + window_size2]     # 다음 날 종가\n",
    "    data_X.append(_X)\n",
    "    data_y.append(_y)\n",
    "print(_X, \"->\", _y)\n",
    "train_size = int(len(data_y) * 0.7)\n",
    "train_X = np.array(data_X[0 : train_size])\n",
    "train_y = np.array(data_y[0 : train_size])\n",
    "\n",
    "test_size = len(data_y) - train_size\n",
    "test_X = np.array(data_X[train_size : len(data_X)])\n",
    "test_y = np.array(data_y[train_size : len(data_y)])\n",
    "\n",
    "print('훈련 데이터의 크기 :', train_X.shape, train_y.shape)\n",
    "print('테스트 데이터의 크기 :', test_X.shape, test_y.shape)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=20, activation='relu', return_sequences=True, input_shape=(10, 4)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=20, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(train_X, train_y, epochs=70, batch_size=30)\n",
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score,f1_score,precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37648028],\n",
       "       [0.3580688 ],\n",
       "       [0.34210157],\n",
       "       [0.33201382],\n",
       "       [0.32540137],\n",
       "       [0.32092744],\n",
       "       [0.3218774 ],\n",
       "       [0.32551104],\n",
       "       [0.3247136 ],\n",
       "       [0.32038078],\n",
       "       [0.31444407],\n",
       "       [0.30651793],\n",
       "       [0.29763222],\n",
       "       [0.28810245],\n",
       "       [0.2820132 ],\n",
       "       [0.277062  ],\n",
       "       [0.27370444],\n",
       "       [0.27209958],\n",
       "       [0.27214912],\n",
       "       [0.27351254],\n",
       "       [0.27665892],\n",
       "       [0.2810237 ],\n",
       "       [0.28725943],\n",
       "       [0.2921675 ],\n",
       "       [0.29620257],\n",
       "       [0.29921257],\n",
       "       [0.3000677 ],\n",
       "       [0.3002208 ],\n",
       "       [0.29923803],\n",
       "       [0.29735336],\n",
       "       [0.29441875],\n",
       "       [0.29086068],\n",
       "       [0.2864465 ],\n",
       "       [0.2817625 ],\n",
       "       [0.27646014],\n",
       "       [0.27221894],\n",
       "       [0.2692346 ],\n",
       "       [0.29470548],\n",
       "       [0.30442265],\n",
       "       [0.30804035],\n",
       "       [0.30851212],\n",
       "       [0.3064786 ],\n",
       "       [0.30369964],\n",
       "       [0.30068368],\n",
       "       [0.29745418],\n",
       "       [0.29658768],\n",
       "       [0.30012405],\n",
       "       [0.30887306],\n",
       "       [0.3123088 ],\n",
       "       [0.3149272 ],\n",
       "       [0.3161756 ],\n",
       "       [0.31638584],\n",
       "       [0.31464937],\n",
       "       [0.31190038],\n",
       "       [0.3091315 ],\n",
       "       [0.30704153],\n",
       "       [0.3056845 ],\n",
       "       [0.304413  ],\n",
       "       [0.30305922],\n",
       "       [0.3016641 ],\n",
       "       [0.30036497],\n",
       "       [0.29911226],\n",
       "       [0.29719326],\n",
       "       [0.29518092],\n",
       "       [0.29377073],\n",
       "       [0.29280677],\n",
       "       [0.2922934 ],\n",
       "       [0.29247957],\n",
       "       [0.29369202],\n",
       "       [0.29723728],\n",
       "       [0.3012324 ],\n",
       "       [0.30364028],\n",
       "       [0.3046297 ],\n",
       "       [0.30561987],\n",
       "       [0.30617726],\n",
       "       [0.30657208],\n",
       "       [0.3060007 ],\n",
       "       [0.30668885],\n",
       "       [0.30804873],\n",
       "       [0.31056252],\n",
       "       [0.3143233 ],\n",
       "       [0.31863946],\n",
       "       [0.32338917],\n",
       "       [0.32817698],\n",
       "       [0.33182362],\n",
       "       [0.33382896],\n",
       "       [0.33407435],\n",
       "       [0.3335874 ],\n",
       "       [0.33332083],\n",
       "       [0.3330821 ],\n",
       "       [0.33454382],\n",
       "       [0.3372223 ],\n",
       "       [0.34055492],\n",
       "       [0.34337506],\n",
       "       [0.3446742 ],\n",
       "       [0.343067  ],\n",
       "       [0.33855745],\n",
       "       [0.33334854],\n",
       "       [0.32994065],\n",
       "       [0.32784358],\n",
       "       [0.32593024],\n",
       "       [0.324414  ],\n",
       "       [0.32220632],\n",
       "       [0.32057464],\n",
       "       [0.31829283],\n",
       "       [0.31600523],\n",
       "       [0.31505385],\n",
       "       [0.31515148],\n",
       "       [0.31574067],\n",
       "       [0.31687504],\n",
       "       [0.31835023],\n",
       "       [0.3196209 ],\n",
       "       [0.31877556],\n",
       "       [0.31738713],\n",
       "       [0.31563196],\n",
       "       [0.31362778],\n",
       "       [0.31206304],\n",
       "       [0.31068334],\n",
       "       [0.31022903],\n",
       "       [0.3093037 ],\n",
       "       [0.30758786],\n",
       "       [0.304095  ],\n",
       "       [0.30030045],\n",
       "       [0.29752874],\n",
       "       [0.29587322],\n",
       "       [0.29635254],\n",
       "       [0.29885966],\n",
       "       [0.30275577],\n",
       "       [0.3059429 ],\n",
       "       [0.30833694],\n",
       "       [0.30919164],\n",
       "       [0.30842844],\n",
       "       [0.30683547],\n",
       "       [0.3055454 ],\n",
       "       [0.30397445],\n",
       "       [0.30260214],\n",
       "       [0.30194432],\n",
       "       [0.3009564 ],\n",
       "       [0.29972425],\n",
       "       [0.29765698],\n",
       "       [0.294806  ],\n",
       "       [0.2924585 ],\n",
       "       [0.2915028 ],\n",
       "       [0.29170862],\n",
       "       [0.292292  ],\n",
       "       [0.2935427 ],\n",
       "       [0.29533815],\n",
       "       [0.2975907 ],\n",
       "       [0.29940245],\n",
       "       [0.30106682],\n",
       "       [0.3032439 ],\n",
       "       [0.30731753],\n",
       "       [0.3119449 ],\n",
       "       [0.31777933],\n",
       "       [0.3232916 ],\n",
       "       [0.3282525 ],\n",
       "       [0.3305481 ],\n",
       "       [0.3303012 ],\n",
       "       [0.32868835],\n",
       "       [0.32581496],\n",
       "       [0.32395586],\n",
       "       [0.32301712],\n",
       "       [0.3237068 ],\n",
       "       [0.3245954 ],\n",
       "       [0.3262151 ],\n",
       "       [0.32682234],\n",
       "       [0.32715932],\n",
       "       [0.3266173 ],\n",
       "       [0.32622984],\n",
       "       [0.32563743],\n",
       "       [0.32548007],\n",
       "       [0.32459357],\n",
       "       [0.3233177 ],\n",
       "       [0.32236308],\n",
       "       [0.32138827],\n",
       "       [0.3203569 ],\n",
       "       [0.3205042 ],\n",
       "       [0.32391042],\n",
       "       [0.32851028],\n",
       "       [0.33457237],\n",
       "       [0.34107292],\n",
       "       [0.34653002],\n",
       "       [0.35198644],\n",
       "       [0.35665435],\n",
       "       [0.36151126],\n",
       "       [0.3680363 ],\n",
       "       [0.37476626],\n",
       "       [0.38919485],\n",
       "       [0.3907047 ],\n",
       "       [0.38806185],\n",
       "       [0.38474718],\n",
       "       [0.38043883],\n",
       "       [0.37595007],\n",
       "       [0.37396854],\n",
       "       [0.37561986],\n",
       "       [0.37798834],\n",
       "       [0.37961078],\n",
       "       [0.38053542],\n",
       "       [0.37995428],\n",
       "       [0.37975013],\n",
       "       [0.37883338],\n",
       "       [0.37835053],\n",
       "       [0.37751806],\n",
       "       [0.37573063],\n",
       "       [0.37249148],\n",
       "       [0.368327  ],\n",
       "       [0.3641318 ],\n",
       "       [0.36022285],\n",
       "       [0.35658044],\n",
       "       [0.35467196],\n",
       "       [0.35426697],\n",
       "       [0.3545433 ],\n",
       "       [0.35445815],\n",
       "       [0.35324597],\n",
       "       [0.35095236],\n",
       "       [0.34780258],\n",
       "       [0.34492615],\n",
       "       [0.3422861 ],\n",
       "       [0.3398882 ],\n",
       "       [0.3380252 ],\n",
       "       [0.33659422],\n",
       "       [0.3356767 ],\n",
       "       [0.33522615],\n",
       "       [0.33431295],\n",
       "       [0.33399278],\n",
       "       [0.33450294],\n",
       "       [0.33589283],\n",
       "       [0.33741623],\n",
       "       [0.33876503],\n",
       "       [0.33959734],\n",
       "       [0.34030694],\n",
       "       [0.33895975],\n",
       "       [0.33518618],\n",
       "       [0.32985064],\n",
       "       [0.3217923 ],\n",
       "       [0.31256548],\n",
       "       [0.30408517],\n",
       "       [0.29596388],\n",
       "       [0.28964806],\n",
       "       [0.28389403],\n",
       "       [0.27970028],\n",
       "       [0.27619535],\n",
       "       [0.27487895],\n",
       "       [0.2744462 ],\n",
       "       [0.27463225],\n",
       "       [0.27463812],\n",
       "       [0.2749559 ],\n",
       "       [0.27571586],\n",
       "       [0.2765307 ],\n",
       "       [0.27628958],\n",
       "       [0.27642214],\n",
       "       [0.27615288],\n",
       "       [0.2762483 ],\n",
       "       [0.276501  ],\n",
       "       [0.27670366],\n",
       "       [0.27821177],\n",
       "       [0.2794133 ],\n",
       "       [0.2810196 ],\n",
       "       [0.2818746 ],\n",
       "       [0.28150356],\n",
       "       [0.2808347 ],\n",
       "       [0.27777797],\n",
       "       [0.27180293],\n",
       "       [0.26390645],\n",
       "       [0.25476062],\n",
       "       [0.24532111],\n",
       "       [0.23597534],\n",
       "       [0.22640854],\n",
       "       [0.21885605],\n",
       "       [0.21161614],\n",
       "       [0.20623103],\n",
       "       [0.20404151],\n",
       "       [0.20388958],\n",
       "       [0.20574489],\n",
       "       [0.20876801],\n",
       "       [0.21110275],\n",
       "       [0.21390687],\n",
       "       [0.21592052],\n",
       "       [0.21659903],\n",
       "       [0.21582307],\n",
       "       [0.21368825],\n",
       "       [0.21133065],\n",
       "       [0.20912859],\n",
       "       [0.20650806],\n",
       "       [0.20366234],\n",
       "       [0.20130484],\n",
       "       [0.1985715 ],\n",
       "       [0.1957033 ],\n",
       "       [0.19257218],\n",
       "       [0.19053234],\n",
       "       [0.18877701],\n",
       "       [0.18633457],\n",
       "       [0.18349297],\n",
       "       [0.18184751],\n",
       "       [0.17982957],\n",
       "       [0.17777184],\n",
       "       [0.17494762],\n",
       "       [0.17300951],\n",
       "       [0.17164387],\n",
       "       [0.16995601],\n",
       "       [0.16766119],\n",
       "       [0.16529009],\n",
       "       [0.16206887],\n",
       "       [0.15886432],\n",
       "       [0.15694524],\n",
       "       [0.15576471],\n",
       "       [0.15568079],\n",
       "       [0.15602633],\n",
       "       [0.15670466],\n",
       "       [0.15755466],\n",
       "       [0.1587828 ],\n",
       "       [0.16010162],\n",
       "       [0.16300507],\n",
       "       [0.16513474],\n",
       "       [0.16578609],\n",
       "       [0.16573773],\n",
       "       [0.16497976],\n",
       "       [0.16356859],\n",
       "       [0.16249967],\n",
       "       [0.16144316],\n",
       "       [0.16018245],\n",
       "       [0.15908487],\n",
       "       [0.15892527],\n",
       "       [0.15895127],\n",
       "       [0.15964201],\n",
       "       [0.160371  ],\n",
       "       [0.16201416],\n",
       "       [0.16339006],\n",
       "       [0.16450018],\n",
       "       [0.16622894],\n",
       "       [0.16747826],\n",
       "       [0.16821364],\n",
       "       [0.16854364],\n",
       "       [0.16851386],\n",
       "       [0.1679292 ],\n",
       "       [0.16799499],\n",
       "       [0.1675519 ],\n",
       "       [0.16714868],\n",
       "       [0.1664385 ],\n",
       "       [0.16476795],\n",
       "       [0.16356672],\n",
       "       [0.16157559],\n",
       "       [0.15923367],\n",
       "       [0.15661022],\n",
       "       [0.15475917],\n",
       "       [0.15279996],\n",
       "       [0.15169385],\n",
       "       [0.15131128],\n",
       "       [0.15115803],\n",
       "       [0.15145236],\n",
       "       [0.15234554],\n",
       "       [0.15393284],\n",
       "       [0.1553937 ],\n",
       "       [0.15731268],\n",
       "       [0.15897183],\n",
       "       [0.16047393],\n",
       "       [0.16180038],\n",
       "       [0.1625067 ],\n",
       "       [0.16290097],\n",
       "       [0.16299036],\n",
       "       [0.16240017],\n",
       "       [0.16191843],\n",
       "       [0.1610608 ],\n",
       "       [0.16037369],\n",
       "       [0.15957713],\n",
       "       [0.1588018 ],\n",
       "       [0.15749142],\n",
       "       [0.1561929 ],\n",
       "       [0.15510431],\n",
       "       [0.15469024],\n",
       "       [0.15473138],\n",
       "       [0.15483458],\n",
       "       [0.15488149],\n",
       "       [0.15473029],\n",
       "       [0.15485197],\n",
       "       [0.15518041],\n",
       "       [0.15644076],\n",
       "       [0.15767696],\n",
       "       [0.1591619 ],\n",
       "       [0.16036893],\n",
       "       [0.16212581],\n",
       "       [0.1636954 ],\n",
       "       [0.16531506],\n",
       "       [0.16657095],\n",
       "       [0.16809945],\n",
       "       [0.16965562],\n",
       "       [0.17055652],\n",
       "       [0.17149717],\n",
       "       [0.1720911 ],\n",
       "       [0.17276238],\n",
       "       [0.17325142],\n",
       "       [0.17410293],\n",
       "       [0.17428148],\n",
       "       [0.17467451],\n",
       "       [0.17498067],\n",
       "       [0.1754694 ],\n",
       "       [0.17673454],\n",
       "       [0.17821825],\n",
       "       [0.18040228],\n",
       "       [0.18284898],\n",
       "       [0.18432349],\n",
       "       [0.18509245],\n",
       "       [0.18550909],\n",
       "       [0.18541157],\n",
       "       [0.1853824 ],\n",
       "       [0.2311575 ],\n",
       "       [0.24993575],\n",
       "       [0.2570152 ],\n",
       "       [0.25717768],\n",
       "       [0.25306764],\n",
       "       [0.2475344 ],\n",
       "       [0.24060054],\n",
       "       [0.23385483],\n",
       "       [0.2286863 ],\n",
       "       [0.22505152],\n",
       "       [0.21380165],\n",
       "       [0.21273273],\n",
       "       [0.21234165],\n",
       "       [0.2124611 ],\n",
       "       [0.21349171],\n",
       "       [0.21310544],\n",
       "       [0.21211573],\n",
       "       [0.2104195 ],\n",
       "       [0.20784916],\n",
       "       [0.20544104],\n",
       "       [0.20325121],\n",
       "       [0.20051894],\n",
       "       [0.20005669],\n",
       "       [0.1991413 ],\n",
       "       [0.19798139],\n",
       "       [0.19769706],\n",
       "       [0.19652888],\n",
       "       [0.19343823],\n",
       "       [0.18863292],\n",
       "       [0.18339205],\n",
       "       [0.17808709],\n",
       "       [0.1723012 ],\n",
       "       [0.16534585],\n",
       "       [0.15848212],\n",
       "       [0.15091169],\n",
       "       [0.14203203],\n",
       "       [0.13454446],\n",
       "       [0.13047552],\n",
       "       [0.12736377],\n",
       "       [0.12465724],\n",
       "       [0.14253849],\n",
       "       [0.14965492],\n",
       "       [0.15319829],\n",
       "       [0.15375663],\n",
       "       [0.15287036],\n",
       "       [0.15226546],\n",
       "       [0.15069458],\n",
       "       [0.14844483],\n",
       "       [0.14635655],\n",
       "       [0.14399037],\n",
       "       [0.13072146],\n",
       "       [0.12787515],\n",
       "       [0.12759504],\n",
       "       [0.12814689],\n",
       "       [0.12912606],\n",
       "       [0.12969267],\n",
       "       [0.12983456],\n",
       "       [0.13037689],\n",
       "       [0.13032743],\n",
       "       [0.12999862],\n",
       "       [0.12997814],\n",
       "       [0.12976806],\n",
       "       [0.12973455],\n",
       "       [0.12943366],\n",
       "       [0.12942955],\n",
       "       [0.12966883],\n",
       "       [0.13036142],\n",
       "       [0.13087295],\n",
       "       [0.13139491],\n",
       "       [0.13207382],\n",
       "       [0.13263786],\n",
       "       [0.13351591],\n",
       "       [0.13411194],\n",
       "       [0.13436294],\n",
       "       [0.13468191],\n",
       "       [0.134823  ],\n",
       "       [0.13469726],\n",
       "       [0.13434412],\n",
       "       [0.13448438],\n",
       "       [0.13437688],\n",
       "       [0.13405259],\n",
       "       [0.1332517 ],\n",
       "       [0.13287379],\n",
       "       [0.13365832],\n",
       "       [0.13376513],\n",
       "       [0.13357022],\n",
       "       [0.13314511],\n",
       "       [0.13337004],\n",
       "       [0.13262348],\n",
       "       [0.1320918 ],\n",
       "       [0.1325894 ],\n",
       "       [0.13280708],\n",
       "       [0.13286108],\n",
       "       [0.1323593 ],\n",
       "       [0.13284531],\n",
       "       [0.1339115 ],\n",
       "       [0.13474897],\n",
       "       [0.13458565],\n",
       "       [0.13393894],\n",
       "       [0.13203542],\n",
       "       [0.12865998],\n",
       "       [0.12611553],\n",
       "       [0.1228078 ],\n",
       "       [0.11982936],\n",
       "       [0.11695111],\n",
       "       [0.11426386],\n",
       "       [0.11252409],\n",
       "       [0.111038  ],\n",
       "       [0.1108503 ],\n",
       "       [0.11032867],\n",
       "       [0.11022618],\n",
       "       [0.10796523],\n",
       "       [0.10811093],\n",
       "       [0.10743557],\n",
       "       [0.10765645],\n",
       "       [0.10940003],\n",
       "       [0.10966972],\n",
       "       [0.10984221],\n",
       "       [0.11057428],\n",
       "       [0.11098579],\n",
       "       [0.11144501],\n",
       "       [0.11180845],\n",
       "       [0.11219504],\n",
       "       [0.11205584],\n",
       "       [0.11161044],\n",
       "       [0.10921678],\n",
       "       [0.10949486],\n",
       "       [0.10967565],\n",
       "       [0.1099245 ],\n",
       "       [0.11026971],\n",
       "       [0.11083671],\n",
       "       [0.11165296],\n",
       "       [0.11317562],\n",
       "       [0.11462316],\n",
       "       [0.11596155],\n",
       "       [0.1169354 ],\n",
       "       [0.11740291],\n",
       "       [0.11740014],\n",
       "       [0.11708036],\n",
       "       [0.11738342],\n",
       "       [0.11741522],\n",
       "       [0.11808965],\n",
       "       [0.11816338],\n",
       "       [0.11820666],\n",
       "       [0.11892284],\n",
       "       [0.12001868],\n",
       "       [0.12113503],\n",
       "       [0.1221287 ],\n",
       "       [0.12247804],\n",
       "       [0.12227628],\n",
       "       [0.12142578],\n",
       "       [0.12002499],\n",
       "       [0.11917239],\n",
       "       [0.11889634],\n",
       "       [0.11830176],\n",
       "       [0.11728176],\n",
       "       [0.11701384],\n",
       "       [0.11668372],\n",
       "       [0.11625364],\n",
       "       [0.11592305],\n",
       "       [0.11546153],\n",
       "       [0.11482434],\n",
       "       [0.1137273 ],\n",
       "       [0.11270049],\n",
       "       [0.11204155],\n",
       "       [0.11087155],\n",
       "       [0.10818443],\n",
       "       [0.10694796],\n",
       "       [0.10538602],\n",
       "       [0.10386296],\n",
       "       [0.10276647],\n",
       "       [0.10181847],\n",
       "       [0.10070294],\n",
       "       [0.09942356],\n",
       "       [0.09847447],\n",
       "       [0.09823786],\n",
       "       [0.09843718],\n",
       "       [0.09818897],\n",
       "       [0.09839293],\n",
       "       [0.09815663],\n",
       "       [0.09839493],\n",
       "       [0.09906863],\n",
       "       [0.09996226],\n",
       "       [0.10105285],\n",
       "       [0.10219562],\n",
       "       [0.10346025],\n",
       "       [0.10509011],\n",
       "       [0.10705763],\n",
       "       [0.10913463],\n",
       "       [0.11114305],\n",
       "       [0.11314498],\n",
       "       [0.11526886]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2D, but have shapes (597,) and (597, 10, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m pred_y \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_X)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39;49mplot(test_y, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m'\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreal SEC stock price\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(pred_y, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredicted SEC stock price\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mSEC stock price prediction\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhm21\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:2785\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2783\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2785\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2786\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2787\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jhm21\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\jhm21\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\jhm21\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:507\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    510\u001b[0m     x \u001b[39m=\u001b[39m x[:, np\u001b[39m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mValueError\u001b[0m: x and y can be no greater than 2D, but have shapes (597,) and (597, 10, 1)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcw0lEQVR4nO3db2zdVf3A8U/b0VsItEzn2m0WKyiiAhturBYkiKk2gUz3wDjBbHPhj+AkuEZlY7CK6DoRyKIrLkwQH6ibEDDGLUOsLgapWdjWBGSDwMBNYwsT184iLWu/vweG+qvrYLf0z077eiX3wY7n3O+5Hkbf3H8tyLIsCwCABBSO9QYAAI6VcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSkXe4/OEPf4h58+bF9OnTo6CgIH75y1++5Zpt27bFRz7ykcjlcvG+970v7r///iFsFQCY6PIOl66urpg5c2Y0NTUd0/wXXnghLrvssrjkkkuitbU1vvrVr8ZVV10VjzzySN6bBQAmtoK380sWCwoK4uGHH4758+cfdc6NN94Ymzdvjqeeeqp/7POf/3wcPHgwtm7dOtRLAwAT0KSRvkBLS0vU1tYOGKurq4uvfvWrR13T3d0d3d3d/X/u6+uLV155Jd75zndGQUHBSG0VABhGWZbFoUOHYvr06VFYODxvqx3xcGlra4vy8vIBY+Xl5dHZ2Rn//ve/48QTTzxiTWNjY9x6660jvTUAYBTs378/3v3udw/LfY14uAzFihUror6+vv/PHR0dcdppp8X+/fujtLR0DHcGAByrzs7OqKysjFNOOWXY7nPEw6WioiLa29sHjLW3t0dpaemgz7ZERORyucjlckeMl5aWChcASMxwvs1jxL/HpaamJpqbmweMPfroo1FTUzPSlwYAxpm8w+Vf//pXtLa2Rmtra0T85+POra2tsW/fvoj4z8s8ixYt6p9/7bXXxt69e+Mb3/hG7NmzJ+6+++74xS9+EcuWLRueRwAATBh5h8sTTzwR5513Xpx33nkREVFfXx/nnXderFq1KiIi/v73v/dHTETEe9/73ti8eXM8+uijMXPmzLjzzjvjRz/6UdTV1Q3TQwAAJoq39T0uo6WzszPKysqio6PDe1wAIBEj8fPb7yoCAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZQwqXpqamqKqqipKSkqiuro7t27e/6fy1a9fGBz7wgTjxxBOjsrIyli1bFq+99tqQNgwATFx5h8umTZuivr4+GhoaYufOnTFz5syoq6uLl156adD5P/vZz2L58uXR0NAQu3fvjnvvvTc2bdoUN91009vePAAwseQdLnfddVdcffXVsWTJkvjQhz4U69evj5NOOinuu+++Qec//vjjceGFF8YVV1wRVVVV8alPfSouv/zyt3yWBgDgf+UVLj09PbFjx46ora397x0UFkZtbW20tLQMuuaCCy6IHTt29IfK3r17Y8uWLXHppZce9Trd3d3R2dk54AYAMCmfyQcOHIje3t4oLy8fMF5eXh579uwZdM0VV1wRBw4ciI997GORZVkcPnw4rr322jd9qaixsTFuvfXWfLYGAEwAI/6pom3btsXq1avj7rvvjp07d8ZDDz0Umzdvjttuu+2oa1asWBEdHR39t/3794/0NgGABOT1jMuUKVOiqKgo2tvbB4y3t7dHRUXFoGtuueWWWLhwYVx11VUREXHOOedEV1dXXHPNNbFy5cooLDyynXK5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQde8+uqrR8RJUVFRRERkWZbvfgGACSyvZ1wiIurr62Px4sUxZ86cmDt3bqxduza6urpiyZIlERGxaNGimDFjRjQ2NkZExLx58+Kuu+6K8847L6qrq+O5556LW265JebNm9cfMAAAxyLvcFmwYEG8/PLLsWrVqmhra4tZs2bF1q1b+9+wu2/fvgHPsNx8881RUFAQN998c/ztb3+Ld73rXTFv3rz4zne+M3yPAgCYEAqyBF6v6ezsjLKysujo6IjS0tKx3g4AcAxG4ue331UEACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhhQuTU1NUVVVFSUlJVFdXR3bt29/0/kHDx6MpUuXxrRp0yKXy8WZZ54ZW7ZsGdKGAYCJa1K+CzZt2hT19fWxfv36qK6ujrVr10ZdXV0888wzMXXq1CPm9/T0xCc/+cmYOnVqPPjggzFjxoz4y1/+Eqeeeupw7B8AmEAKsizL8llQXV0d559/fqxbty4iIvr6+qKysjKuv/76WL58+RHz169fH9/73vdiz549ccIJJwxpk52dnVFWVhYdHR1RWlo6pPsAAEbXSPz8zuulop6entixY0fU1tb+9w4KC6O2tjZaWloGXfOrX/0qampqYunSpVFeXh5nn312rF69Onp7e496ne7u7ujs7BxwAwDIK1wOHDgQvb29UV5ePmC8vLw82traBl2zd+/eePDBB6O3tze2bNkSt9xyS9x5553x7W9/+6jXaWxsjLKysv5bZWVlPtsEAMapEf9UUV9fX0ydOjXuueeemD17dixYsCBWrlwZ69evP+qaFStWREdHR/9t//79I71NACABeb05d8qUKVFUVBTt7e0Dxtvb26OiomLQNdOmTYsTTjghioqK+sc++MEPRltbW/T09ERxcfERa3K5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQddceOGF8dxzz0VfX1//2LPPPhvTpk0bNFoAAI4m75eK6uvrY8OGDfGTn/wkdu/eHdddd110dXXFkiVLIiJi0aJFsWLFiv751113Xbzyyitxww03xLPPPhubN2+O1atXx9KlS4fvUQAAE0Le3+OyYMGCePnll2PVqlXR1tYWs2bNiq1bt/a/YXffvn1RWPjfHqqsrIxHHnkkli1bFueee27MmDEjbrjhhrjxxhuH71EAABNC3t/jMhZ8jwsApGfMv8cFAGAsCRcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIxpDCpampKaqqqqKkpCSqq6tj+/btx7Ru48aNUVBQEPPnzx/KZQGACS7vcNm0aVPU19dHQ0ND7Ny5M2bOnBl1dXXx0ksvvem6F198Mb72ta/FRRddNOTNAgATW97hctddd8XVV18dS5YsiQ996EOxfv36OOmkk+K+++476pre3t74whe+ELfeemucfvrpb3mN7u7u6OzsHHADAMgrXHp6emLHjh1RW1v73zsoLIza2tpoaWk56rpvfetbMXXq1LjyyiuP6TqNjY1RVlbWf6usrMxnmwDAOJVXuBw4cCB6e3ujvLx8wHh5eXm0tbUNuuaxxx6Le++9NzZs2HDM11mxYkV0dHT03/bv35/PNgGAcWrSSN75oUOHYuHChbFhw4aYMmXKMa/L5XKRy+VGcGcAQIryCpcpU6ZEUVFRtLe3Dxhvb2+PioqKI+Y///zz8eKLL8a8efP6x/r6+v5z4UmT4plnnokzzjhjKPsGACagvF4qKi4ujtmzZ0dzc3P/WF9fXzQ3N0dNTc0R888666x48skno7W1tf/26U9/Oi655JJobW313hUAIC95v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExSkpK4uyzzx6w/tRTT42IOGIcAOCt5B0uCxYsiJdffjlWrVoVbW1tMWvWrNi6dWv/G3b37dsXhYW+kBcAGH4FWZZlY72Jt9LZ2RllZWXR0dERpaWlY70dAOAYjMTPb0+NAADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjCGFS1NTU1RVVUVJSUlUV1fH9u3bjzp3w4YNcdFFF8XkyZNj8uTJUVtb+6bzAQCOJu9w2bRpU9TX10dDQ0Ps3LkzZs6cGXV1dfHSSy8NOn/btm1x+eWXx+9///toaWmJysrK+NSnPhV/+9vf3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5e/5fre3t6YPHlyrFu3LhYtWjTonO7u7uju7u7/c2dnZ1RWVkZHR0eUlpbms10AYIx0dnZGWVnZsP78zusZl56entixY0fU1tb+9w4KC6O2tjZaWlqO6T5effXVeP311+Md73jHUec0NjZGWVlZ/62ysjKfbQIA41Re4XLgwIHo7e2N8vLyAePl5eXR1tZ2TPdx4403xvTp0wfEz/9asWJFdHR09N/279+fzzYBgHFq0mhebM2aNbFx48bYtm1blJSUHHVeLpeLXC43ijsDAFKQV7hMmTIlioqKor29fcB4e3t7VFRUvOnaO+64I9asWRO//e1v49xzz81/pwDAhJfXS0XFxcUxe/bsaG5u7h/r6+uL5ubmqKmpOeq622+/PW677bbYunVrzJkzZ+i7BQAmtLxfKqqvr4/FixfHnDlzYu7cubF27dro6uqKJUuWRETEokWLYsaMGdHY2BgREd/97ndj1apV8bOf/Syqqqr63wtz8sknx8knnzyMDwUAGO/yDpcFCxbEyy+/HKtWrYq2traYNWtWbN26tf8Nu/v27YvCwv8+kfPDH/4wenp64rOf/eyA+2loaIhvfvObb2/3AMCEkvf3uIyFkfgcOAAwssb8e1wAAMaScAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkDClcmpqaoqqqKkpKSqK6ujq2b9/+pvMfeOCBOOuss6KkpCTOOeec2LJly5A2CwBMbHmHy6ZNm6K+vj4aGhpi586dMXPmzKirq4uXXnpp0PmPP/54XH755XHllVfGrl27Yv78+TF//vx46qmn3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5cfMX/BggXR1dUVv/71r/vHPvrRj8asWbNi/fr1g16ju7s7uru7+//c0dERp512Wuzfvz9KS0vz2S4AMEY6OzujsrIyDh48GGVlZcNyn5PymdzT0xM7duyIFStW9I8VFhZGbW1ttLS0DLqmpaUl6uvrB4zV1dXFL3/5y6Nep7GxMW699dYjxisrK/PZLgBwHPjHP/4xNuFy4MCB6O3tjfLy8gHj5eXlsWfPnkHXtLW1DTq/ra3tqNdZsWLFgNg5ePBgvOc974l9+/YN2wNnaN6oZ89+jT1ncfxwFscX53H8eOMVk3e84x3Ddp95hctoyeVykcvljhgvKyvzD+FxorS01FkcJ5zF8cNZHF+cx/GjsHD4PsSc1z1NmTIlioqKor29fcB4e3t7VFRUDLqmoqIir/kAAEeTV7gUFxfH7Nmzo7m5uX+sr68vmpubo6amZtA1NTU1A+ZHRDz66KNHnQ8AcDR5v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExIiJuuOGGuPjii+POO++Myy67LDZu3BhPPPFE3HPPPcd8zVwuFw0NDYO+fMTochbHD2dx/HAWxxfncfwYibPI++PQERHr1q2L733ve9HW1hazZs2K73//+1FdXR0RER//+Mejqqoq7r///v75DzzwQNx8883x4osvxvvf//64/fbb49JLLx22BwEATAxDChcAgLHgdxUBAMkQLgBAMoQLAJAM4QIAJOO4CZempqaoqqqKkpKSqK6uju3bt7/p/AceeCDOOuusKCkpiXPOOSe2bNkySjsd//I5iw0bNsRFF10UkydPjsmTJ0dtbe1bnh3HLt+/F2/YuHFjFBQUxPz580d2gxNIvmdx8ODBWLp0aUybNi1yuVyceeaZ/j01TPI9i7Vr18YHPvCBOPHEE6OysjKWLVsWr7322ijtdvz6wx/+EPPmzYvp06dHQUHBm/4Owjds27YtPvKRj0Qul4v3ve99Az6BfMyy48DGjRuz4uLi7L777sv+/Oc/Z1dffXV26qmnZu3t7YPO/+Mf/5gVFRVlt99+e/b0009nN998c3bCCSdkTz755CjvfPzJ9yyuuOKKrKmpKdu1a1e2e/fu7Itf/GJWVlaW/fWvfx3lnY8/+Z7FG1544YVsxowZ2UUXXZR95jOfGZ3NjnP5nkV3d3c2Z86c7NJLL80ee+yx7IUXXsi2bduWtba2jvLOx598z+KnP/1plsvlsp/+9KfZCy+8kD3yyCPZtGnTsmXLlo3yzsefLVu2ZCtXrsweeuihLCKyhx9++E3n7927NzvppJOy+vr67Omnn85+8IMfZEVFRdnWrVvzuu5xES5z587Nli5d2v/n3t7ebPr06VljY+Og8z/3uc9ll1122YCx6urq7Etf+tKI7nMiyPcs/tfhw4ezU045JfvJT34yUlucMIZyFocPH84uuOCC7Ec/+lG2ePFi4TJM8j2LH/7wh9npp5+e9fT0jNYWJ4x8z2Lp0qXZJz7xiQFj9fX12YUXXjii+5xojiVcvvGNb2Qf/vCHB4wtWLAgq6ury+taY/5SUU9PT+zYsSNqa2v7xwoLC6O2tjZaWloGXdPS0jJgfkREXV3dUedzbIZyFv/r1Vdfjddff31YfxPoRDTUs/jWt74VU6dOjSuvvHI0tjkhDOUsfvWrX0VNTU0sXbo0ysvL4+yzz47Vq1dHb2/vaG17XBrKWVxwwQWxY8eO/peT9u7dG1u2bPElqGNguH52j/lvhz5w4ED09vZGeXn5gPHy8vLYs2fPoGva2toGnd/W1jZi+5wIhnIW/+vGG2+M6dOnH/EPJ/kZylk89thjce+990Zra+so7HDiGMpZ7N27N373u9/FF77whdiyZUs899xz8eUvfzlef/31aGhoGI1tj0tDOYsrrrgiDhw4EB/72Mciy7I4fPhwXHvttXHTTTeNxpb5f472s7uzszP+/e9/x4knnnhM9zPmz7gwfqxZsyY2btwYDz/8cJSUlIz1diaUQ4cOxcKFC2PDhg0xZcqUsd7OhNfX1xdTp06Ne+65J2bPnh0LFiyIlStXxvr168d6axPOtm3bYvXq1XH33XfHzp0746GHHorNmzfHbbfdNtZbY4jG/BmXKVOmRFFRUbS3tw8Yb29vj4qKikHXVFRU5DWfYzOUs3jDHXfcEWvWrInf/va3ce65547kNieEfM/i+eefjxdffDHmzZvXP9bX1xcREZMmTYpnnnkmzjjjjJHd9Dg1lL8X06ZNixNOOCGKior6xz74wQ9GW1tb9PT0RHFx8YjuebwaylnccsstsXDhwrjqqqsiIuKcc86Jrq6uuOaaa2LlypVRWOi/30fL0X52l5aWHvOzLRHHwTMuxcXFMXv27Ghubu4f6+vri+bm5qipqRl0TU1NzYD5ERGPPvroUedzbIZyFhERt99+e9x2222xdevWmDNnzmhsddzL9yzOOuusePLJJ6O1tbX/9ulPfzouueSSaG1tjcrKytHc/rgylL8XF154YTz33HP98RgR8eyzz8a0adNEy9swlLN49dVXj4iTN4Iy86v6RtWw/ezO733DI2Pjxo1ZLpfL7r///uzpp5/OrrnmmuzUU0/N2trasizLsoULF2bLly/vn//HP/4xmzRpUnbHHXdku3fvzhoaGnwcepjkexZr1qzJiouLswcffDD7+9//3n87dOjQWD2EcSPfs/hfPlU0fPI9i3379mWnnHJK9pWvfCV75plnsl//+tfZ1KlTs29/+9tj9RDGjXzPoqGhITvllFOyn//859nevXuz3/zmN9kZZ5yRfe5znxurhzBuHDp0KNu1a1e2a9euLCKyu+66K9u1a1f2l7/8JcuyLFu+fHm2cOHC/vlvfBz661//erZ79+6sqakp3Y9DZ1mW/eAHP8hOO+20rLi4OJs7d272pz/9qf9/u/jii7PFixcPmP+LX/wiO/PMM7Pi4uLswx/+cLZ58+ZR3vH4lc9ZvOc978ki4ohbQ0PD6G98HMr378X/J1yGV75n8fjjj2fV1dVZLpfLTj/99Ow73/lOdvjw4VHe9fiUz1m8/vrr2Te/+c3sjDPOyEpKSrLKysrsy1/+cvbPf/5z9Dc+zvz+978f9N//b/z/v3jx4uziiy8+Ys2sWbOy4uLi7PTTT89+/OMf533dgizzXBkAkIYxf48LAMCxEi4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJCM/wM9kKRvAVrZIAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = model.predict(test_X)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_y, color='red', label='real SEC stock price')\n",
    "plt.plot(pred_y, color='blue', label='predicted SEC stock price')\n",
    "plt.title('SEC stock price prediction')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('stock price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"내일 SEC 주가 :\", df.Close[-1] * pred_y[-1] / dfy.Close[-1], 'KRW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5a5dc7eaf6385803b22ee4c0eae49f795df80ca0ed2632526c2d48e4adae873"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
